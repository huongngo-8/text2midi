{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq\n",
      "  Using cached fairseq-1.0.0a0+3369427-cp39-cp39-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (2.3.1)\n",
      "Requirement already satisfied: cffi in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (1.15.1)\n",
      "Requirement already satisfied: regex in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (2023.5.5)\n",
      "Requirement already satisfied: numpy in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (1.23.3)\n",
      "Requirement already satisfied: omegaconf<2.1 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (2.0.6)\n",
      "Requirement already satisfied: cython in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (0.29.34)\n",
      "Requirement already satisfied: hydra-core<1.1 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (1.0.7)\n",
      "Requirement already satisfied: tqdm in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (4.65.0)\n",
      "Requirement already satisfied: torch in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from fairseq) (2.0.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from hydra-core<1.1->fairseq) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from omegaconf<2.1->fairseq) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from omegaconf<2.1->fairseq) (4.6.1)\n",
      "Requirement already satisfied: lxml in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq) (2.7.0)\n",
      "Requirement already satisfied: colorama in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
      "Requirement already satisfied: pycparser in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from cffi->fairseq) (2.21)\n",
      "Requirement already satisfied: sympy in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from torch->fairseq) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from torch->fairseq) (3.1)\n",
      "Requirement already satisfied: filelock in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from torch->fairseq) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from torch->fairseq) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from jinja2->torch->fairseq) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages (from sympy->torch->fairseq) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pytorch/fairseq@336942734c85791a90baa373c212d27e7c722662#egg=fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.3\n",
      "  Downloading numpy-1.23.3-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.23.3\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disable_cp = False\n",
      "mask_strategy = ['bar']\n",
      "convert_encoding = OCTMIDI\n",
      "crop_length = None\n"
     ]
    }
   ],
   "source": [
    "from musicbert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_max = 256 #@param {type:\"integer\"}\n",
    "pos_resolution = 16  # per beat (quarter note)\n",
    "velocity_quant = 4\n",
    "tempo_quant = 12  # 2 ** (1 / 12)\n",
    "min_tempo = 16\n",
    "max_tempo = 256\n",
    "duration_max = 8  # 2 ** 8 * beat\n",
    "max_ts_denominator = 6  # x/1 x/2 x/4 ... x/64\n",
    "max_notes_per_bar = 2  # 1/64 ... 128/64\n",
    "beat_note_factor = 4  # In MIDI format a note is always 4 beats\n",
    "deduplicate = True\n",
    "filter_symbolic = False\n",
    "filter_symbolic_ppl = 16\n",
    "trunc_pos = 2 ** 16  # approx 30 minutes (1024 measures)\n",
    "sample_len_max = 1000  # window length max\n",
    "sample_overlap_rate = 4\n",
    "ts_filter = False\n",
    "pool_num = 24\n",
    "max_inst = 127\n",
    "max_pitch = 127\n",
    "max_velocity = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2e(x):\n",
    "    assert x in ts_dict, 'unsupported time signature: ' + str(x)\n",
    "    return ts_dict[x]\n",
    "\n",
    "\n",
    "def e2t(x):\n",
    "    return ts_list[x]\n",
    "\n",
    "\n",
    "def d2e(x):\n",
    "    return dur_enc[x] if x < len(dur_enc) else dur_enc[-1]\n",
    "\n",
    "\n",
    "def e2d(x):\n",
    "    return dur_dec[x] if x < len(dur_dec) else dur_dec[-1]\n",
    "\n",
    "\n",
    "def v2e(x):\n",
    "    return x // velocity_quant\n",
    "\n",
    "\n",
    "def e2v(x):\n",
    "    return (x * velocity_quant) + (velocity_quant // 2)\n",
    "\n",
    "\n",
    "def b2e(x):\n",
    "    x = max(x, min_tempo)\n",
    "    x = min(x, max_tempo)\n",
    "    x = x / min_tempo\n",
    "    e = round(math.log2(x) * tempo_quant)\n",
    "    return e\n",
    "\n",
    "\n",
    "def e2b(x):\n",
    "    return 2 ** (x / tempo_quant) * min_tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dictionary(file_name):\n",
    "    num = 0\n",
    "    with open(file_name, 'w') as f:\n",
    "        for j in range(bar_max):\n",
    "            print('<0-{}>'.format(j), num, file=f)\n",
    "        for j in range(beat_note_factor * max_notes_per_bar * pos_resolution):\n",
    "            print('<1-{}>'.format(j), num, file=f)\n",
    "        for j in range(max_inst + 1 + 1):\n",
    "            # max_inst + 1 for percussion\n",
    "            print('<2-{}>'.format(j), num, file=f)\n",
    "        for j in range(2 * max_pitch + 1 + 1):\n",
    "            # max_pitch + 1 ~ 2 * max_pitch + 1 for percussion\n",
    "            print('<3-{}>'.format(j), num, file=f)\n",
    "        for j in range(duration_max * pos_resolution):\n",
    "            print('<4-{}>'.format(j), num, file=f)\n",
    "        for j in range(v2e(max_velocity) + 1):\n",
    "            print('<5-{}>'.format(j), num, file=f)\n",
    "        for j in range(len(ts_list)):\n",
    "            print('<6-{}>'.format(j), num, file=f)\n",
    "        for j in range(b2e(max_tempo) + 1):\n",
    "            print('<7-{}>'.format(j), num, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dict = dict()\n",
    "ts_list = list()\n",
    "for i in range(0, max_ts_denominator + 1):  # 1 ~ 64\n",
    "    for j in range(1, ((2 ** i) * max_notes_per_bar) + 1):\n",
    "        ts_dict[(j, 2 ** i)] = len(ts_dict)\n",
    "        ts_list.append((j, 2 ** i))\n",
    "dur_enc = list()\n",
    "dur_dec = list()\n",
    "for i in range(duration_max):\n",
    "    for j in range(pos_resolution):\n",
    "        dur_dec.append(len(dur_enc))\n",
    "        for k in range(2 ** i):\n",
    "            dur_enc.append(len(dur_dec) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p input0\n",
    "ROOT = '/Users/huongngo/Desktop/RESEARCH/text-to-midi/muzic/musicbert/input0' \n",
    "gen_dictionary('{}/dict.txt'.format(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p label\n",
    "ROOT = '/Users/huongngo/Desktop/RESEARCH/text-to-midi/muzic/musicbert/label' \n",
    "gen_dictionary('{}/dict.txt'.format(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/huongngo/opt/anaconda3/envs/temp/lib/python3.9/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1-BW45Vu80GU86ejTT4PFkgjvDhhYWatS\n",
      "From (redirected): https://drive.google.com/uc?id=1-BW45Vu80GU86ejTT4PFkgjvDhhYWatS&confirm=t&uuid=1caa71ee-3fe4-403f-85d6-67fe1018d831\n",
      "To: /Users/huongngo/Desktop/RESEARCH/text-to-midi/muzic/musicbert/checkpoint_last_musicbert_small_w_genre_head.pt\n",
      "100%|████████████████████████████████████████| 267M/267M [00:30<00:00, 8.77MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1-BW45Vu80GU86ejTT4PFkgjvDhhYWatS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/huongngo/Desktop/RESEARCH/text-to-midi/muzic/musicbert/label/dict.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m roberta_base \u001b[39m=\u001b[39m MusicBERTModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      2\u001b[0m   checkpoint_file \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/Users/huongngo/Desktop/RESEARCH/text-to-midi/checkpoints/checkpoint_last_musicbert_small_w_genre_head.pt\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m   user_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmusicbert\u001b[39;49m\u001b[39m'\u001b[39;49m    \u001b[39m# activate the MusicBERT plugin with this keyword\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/models/roberta/model.py:244\u001b[0m, in \u001b[0;36mRobertaModel.from_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, bpe, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\n\u001b[1;32m    235\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    241\u001b[0m ):\n\u001b[1;32m    242\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m \u001b[39mimport\u001b[39;00m hub_utils\n\u001b[0;32m--> 244\u001b[0m     x \u001b[39m=\u001b[39m hub_utils\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    245\u001b[0m         model_name_or_path,\n\u001b[1;32m    246\u001b[0m         checkpoint_file,\n\u001b[1;32m    247\u001b[0m         data_name_or_path,\n\u001b[1;32m    248\u001b[0m         archive_map\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mhub_models(),\n\u001b[1;32m    249\u001b[0m         bpe\u001b[39m=\u001b[39;49mbpe,\n\u001b[1;32m    250\u001b[0m         load_checkpoint_heads\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    251\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    254\u001b[0m     logger\u001b[39m.\u001b[39minfo(x[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m RobertaHubInterface(x[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m], x[\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m], x[\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/hub_utils.py:73\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser_dir\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m     71\u001b[0m     utils\u001b[39m.\u001b[39mimport_user_module(argparse\u001b[39m.\u001b[39mNamespace(user_dir\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39muser_dir\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m---> 73\u001b[0m models, args, task \u001b[39m=\u001b[39m checkpoint_utils\u001b[39m.\u001b[39;49mload_model_ensemble_and_task(\n\u001b[1;32m     74\u001b[0m     [os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(model_path, cpt) \u001b[39mfor\u001b[39;49;00m cpt \u001b[39min\u001b[39;49;00m checkpoint_file\u001b[39m.\u001b[39;49msplit(os\u001b[39m.\u001b[39;49mpathsep)],\n\u001b[1;32m     75\u001b[0m     arg_overrides\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     79\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[1;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m: task,\n\u001b[1;32m     81\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m: models,\n\u001b[1;32m     82\u001b[0m }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/checkpoint_utils.py:350\u001b[0m, in \u001b[0;36mload_model_ensemble_and_task\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards, state)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    346\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNeither args nor cfg exist in state keys = \u001b[39m\u001b[39m{\u001b[39;00mstate\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     task \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39;49msetup_task(cfg\u001b[39m.\u001b[39;49mtask)\n\u001b[1;32m    352\u001b[0m \u001b[39m# build model for ensemble\u001b[39;00m\n\u001b[1;32m    353\u001b[0m model \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mbuild_model(cfg\u001b[39m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/tasks/__init__.py:44\u001b[0m, in \u001b[0;36msetup_task\u001b[0;34m(cfg, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         task \u001b[39m=\u001b[39m TASK_REGISTRY[task_name]\n\u001b[1;32m     42\u001b[0m \u001b[39massert\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not infer task type from \u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mreturn\u001b[39;00m task\u001b[39m.\u001b[39;49msetup_task(cfg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/tasks/sentence_prediction.py:125\u001b[0m, in \u001b[0;36mSentencePredictionTask.setup_task\u001b[0;34m(cls, args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m label_dict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mregression_target:\n\u001b[1;32m    124\u001b[0m     \u001b[39m# load label dictionary\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     label_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload_dictionary(\n\u001b[1;32m    126\u001b[0m         args,\n\u001b[1;32m    127\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(args\u001b[39m.\u001b[39;49mdata, \u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdict.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    128\u001b[0m         source\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    130\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m[label] dictionary: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m types\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(label_dict)))\n\u001b[1;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/tasks/sentence_prediction.py:106\u001b[0m, in \u001b[0;36mSentencePredictionTask.load_dictionary\u001b[0;34m(cls, args, filename, source)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dictionary\u001b[39m(\u001b[39mcls\u001b[39m, args, filename, source\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    101\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load the dictionary from the filename\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m        filename (str): the filename\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     dictionary \u001b[39m=\u001b[39m Dictionary\u001b[39m.\u001b[39;49mload(filename)\n\u001b[1;32m    107\u001b[0m     dictionary\u001b[39m.\u001b[39madd_symbol(\u001b[39m\"\u001b[39m\u001b[39m<mask>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m dictionary\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/data/dictionary.py:215\u001b[0m, in \u001b[0;36mDictionary.load\u001b[0;34m(cls, f)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads the dictionary from a text file with the format:\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[0;32m--> 215\u001b[0m d\u001b[39m.\u001b[39;49madd_from_file(f)\n\u001b[1;32m    216\u001b[0m \u001b[39mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/data/dictionary.py:228\u001b[0m, in \u001b[0;36mDictionary.add_from_file\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_from_file(fd)\n\u001b[1;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m fnfe:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m fnfe\n\u001b[1;32m    229\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeError\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIncorrect encoding detected in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrebuild the dataset\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(f)\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.9/site-packages/fairseq/data/dictionary.py:225\u001b[0m, in \u001b[0;36mDictionary.add_from_file\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(PathManager\u001b[39m.\u001b[39;49mget_local_path(f), \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m fd:\n\u001b[1;32m    226\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_from_file(fd)\n\u001b[1;32m    227\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m fnfe:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/huongngo/Desktop/RESEARCH/text-to-midi/muzic/musicbert/label/dict.txt'"
     ]
    }
   ],
   "source": [
    "roberta_base = MusicBERTModel.from_pretrained('.', \n",
    "  checkpoint_file = '/Users/huongngo/Desktop/RESEARCH/text-to-midi/checkpoints/checkpoint_last_musicbert_small_w_genre_head.pt',\n",
    "  user_dir='musicbert'    # activate the MusicBERT plugin with this keyword\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaHubInterface(\n",
      "  (model): MusicBERTModel(\n",
      "    (encoder): MusicBERTEncoder(\n",
      "      (sentence_encoder): OctupleEncoder(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (embed_tokens): Embedding(1237, 512, padding_idx=1)\n",
      "        (embed_positions): LearnedPositionalEmbedding(8194, 512, padding_idx=1)\n",
      "        (emb_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (layers): ModuleList(\n",
      "          (0-3): 4 x TransformerSentenceEncoderLayer(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (activation_dropout_module): FairseqDropout()\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (dropout_module): FairseqDropout()\n",
      "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (downsampling): Sequential(\n",
      "          (0): Linear(in_features=4096, out_features=512, bias=True)\n",
      "        )\n",
      "        (upsampling): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (lm_head): RobertaLMHead(\n",
      "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (classification_heads): ModuleDict(\n",
      "      (topmagd_head): RobertaClassificationHead(\n",
      "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=512, out_features=13, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(roberta_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gehirn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
